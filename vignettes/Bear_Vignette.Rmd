---
title: "rovquantR : a R package to reproduce RovQuant analyses"
subtitle : "Norwegian bear population"
author: "Pierre Dupont"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: references.bib  
vignette: >
  %\VignetteIndexEntry{Wolverine Example}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: sentence
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# rovquantR <a href="https://www.nmbu.no/en/research/projects/rovquant"><img src="inst/images/RovQuant.png" align="right" height="180"/></a>

<h4 align="center">

A user-friendly interface to reproduce RovQuant's analyses.

</h4>

------------------------------------------------------------------------

Large carnivores are rare, elusive, and controversial.
Their populations are difficult to monitor and manage.
For over 10 years, Swedish and Norwegian authorities have been accumulating monitoring data in [**Rovbase**](https://rovbase.no/), an international large carnivore database.
Today, the database contains records from thousands of non-invasive genetic samples, observations, and dead recoveries of bears, wolves, and wolverines, collected by managers, researchers, hunters, and other members of the public in Scandinavia.

Since 2017, project [**RovQuant**](https://www.nmbu.no/en/research/projects/rovquant) from the Applied Quantitative Ecology Group ([**AQEG**](https://www.nmbu.no/en/research/groups/applied-quantitative-ecology-group-aqeg)) has developed and tested statistical methods for the analysis of this unique database.
The different goals of this international research project are to:

1.  **Estimate carnivore population sizes and map carnivore densities.** RovQuant provides population size estimates for wolves, bears, and wolverines throughout Norway and Sweden annually.
    RovQuant also generates carnivore density surfaces - maps of the density of wolverines, wolves, and bears - across Norway and Sweden.
    These maps and the underlying data are freely available.

2.  **Estimate population vital rates.** Population dynamics are the result of the combination of mortality, recruitment, immigration, and emigration.
    Population vital rates thus drive changes in wildlife population over time.
    Monitoring conducted over multiple years allows RovQuant to estimate vital rates of large carnivores in Scandinavia.
    These estimates, in turn, are a prerequisite for population forecasting.

3.  **Further develop monitoring protocols**.
    RovQuant aims to help authorities develop protocols for the cost-efficient collection of non-invasive sampling data.
    Properly designed and executed monitoring leads to reliable data, and reliable data are a pre-requisite for producing trustworthy estimates and conclusions.
    This is particularly important when scientific results inform policy decisions and wildlife management.

4.  **Collaborate with managers.** The project results are published annually in technical reports.
    In addition, members from the project's team regularly attend meetings and workshops to ensure that RovQuant remains up-to-date on current and emerging challenges in large carnivore monitoring and management.

The methods developed by the RovQuant team are based on the Spatial Capture-Recapture (SCR) methodology and involve large-scale analysis of individual-based datasets in a Bayesian framework.
Spatial Capture-Recapture (SCR) methods use the spatial information contained in individual detections, for example DNA samples left behind by wildlife, to estimate the location of activity centers of all individuals in the population, including those never detected.
SCR models thus produce density estimates and density surfaces, while accounting for the fact that not all individuals are detected.
Furthermore, abundance estimates produced by SCR models take into account that animals move across the landscape and may be detected in multiple locations â€“ for example, a bear living near the Swedish-Norwegian border may contribute partially to population size estimates in both countries.
These developments were conducted in collaboration with the [**NIMBLE**](https://r-nimble.org/) development team, and led to the publication of the [`nimbleSCR`](https://cran.r-project.org/web/packages/nimbleSCR/index.html) `R` package, which compiles a set of custom functions and distributions allowing to build custom SCR models and fit them to large-scale datasets in an efficient manner.

In addition, the RovQuant team has recently developed the `rovquantR` package to facilitate the reproduction of their most recent analyses.
In this vignette, we present the workflow used for the analysis of the Norwegian portion of the Brown bear non-invasive genetic monitoring data using the `rovquantR` package.
This analysis consists in the Open-Population Spatial Capture-Recapture (OPSCR) analysis of the non-invasive genetic sampling and dead recovery data collected by the Norwegian authorities between 2015 and 2024 and available in Rovbase as of June 2025.

# Package Installation

Before we can start the analysis, we need to make sure that our `R` session is adequately configured and that we have all the `R` libraries required.
The first requirement is to have `Rtools` is installed.
To check if `Rtools` is correctly installed, we can use the function `has_rtools()` from the `pkgbuild` package.
Note that `Rtools` is not a `R` package *per se* and cannot be installed directly from your `R` session.
If it is not already installed, please refer to the [Rtools CRAN page](https://cran.r-project.org/bin/windows/Rtools/) for instructions.

```{r Rtools1, echo = TRUE, eval = FALSE}
install.packages("pkgbuild")
library(pkgbuild)
has_rtools()
```

```{r Rtools2, echo = FALSE, eval = TRUE}
library(pkgbuild) 
has_rtools()
```

Once we have ensured `Rtools` is available, we can install and load the `nimbleSCR` package, which contains some of the functions and distributions used in the OPSCR model.

```{r nimbleSCR1, echo = TRUE, eval = FALSE}
install.packages("nimbleSCR")
library(nimbleSCR)
```

```{r nimbleSCR2, echo = FALSE, eval = TRUE}
library(nimbleSCR)
```

Now, we can install the `rovquantR` package.
Because it is not yet available on CRAN, we have to install it from the GitHub repository using the `devtools` package.

```{r gitInstall, eval = FALSE}
install.packages("devtools")
library(devtools)
install_github("PierreDupont/rovquantR")
```

Alternatively, we can install it from the **.tar.gz** file that was provided:

```{r tarInstall, eval = TRUE}
install.packages( "C:/My_documents/rovquantR/rovquantR_0.1.tar.gz",
                  repos = NULL,
                  type = "source") 
```

Finally, we can load the `rovquantR` package and start the analysis:

```{r rovquantR, eval = TRUE}
library(rovquantR)
```

# RovQuant OPSCR Analysis

## Working environment

The first step of the analysis consists in setting-up the working environment.
For this, we need to set-up two paths:

1.  `data.dir`: a path to the repository containing the raw data.
    It contains the different files necessary for the OPSCR analysis:

    -   an excel file of all the brown bear DNA samples available from Rovbase

    -   an excel file of all the brown bear dead recoveries available from Rovbase

    -   an excel file of all large carnivore observations available from Skandobs

    -   multiple spatial covariates (*e.g.* snow cover, distance to roads, .... , in the 'GIS' folder)

    Note that this is NOT the working directory.
    For all intent and purposes, it should be treated as a 'read-only' directory.

```{r set-up1.1, eval = FALSE, echo = TRUE}
data.dir <- "./Data"  
```

```{r set-up1.2, eval = TRUE, echo = FALSE}
data.dir <- "C:/Users/pidu/AQEG Dropbox/AQEG Team Folder/RovQuant/bear/2025/Data"
```

2.  `working.dir`: the repository that will be used to store all the files and outputs from the analysis.

```{r set-up2.1, eval = FALSE, echo = TRUE}
working.dir <- "./BearVignette"
```

```{r set-up2.2, eval = TRUE, echo = FALSE}
working.dir <- "C:/Users/pidu/AQEG Dropbox/AQEG Team Folder/RovQuant/bear/2025/BearVignette"
```

## Data cleaning

Before we dive in the OPSCR analysis itself, there is one more step we need to take.
The raw files exported from Rovbase contain variable column names and Scandinavian characters which make it cumbersome to work with in `R`.
In addition, not all data available from Rovbase can be used in the OPSCR analysis, *i.e.* samples with missing individual ID, date or coordinates.
We therefore need to perform a few cleaning steps before the data can be used.
This step involves, among other actions, subsetting the data to the species and period of interest for the analysis, checking individual sex assigments, removing samples without coordinates, dates or individual ID, removing any samples that were flagged as incorrect, ...

For simplicity, the cleaning process was packaged in the `cleanRovbaseData` function.
This function creates the adequate folder structure in `working.dir` to store all files and outputs linked with the analysis, performs the initial cleaning of the Rovbase data files, and prints out a report in `.html` format summarizing the content of the cleaned dataset.
This report can be found in the `report` folder of the working directory, labeled with the date corresponding to the last modification date of the raw data.

```{r cleanRovbaseData, eval = TRUE}
cleanRovbaseData( 
  species = "bear",
  years = 2020:2025,
  data.dir = data.dir,
  working.dir = working.dir,
  print.report = TRUE)
```

## Data preparation

Now that we have cleaned out the data, it is time to format it for analysis using `nimbleSCR`.
This process can be quite opaque and complex and this is why we have created the `makeRovquantData` wrapper function, which encapsulates the latest data formatting scripts for the different species.

Similar to the `cleanRovbaseData` function, this function produces an `.html` report in the `report` folder, which summarizes the different steps required to prepare the data for the OPSCR analysis, as well as the content of the data going into the model.

```{r makeRovquantData, eval = TRUE}
makeRovquantData(    
  species = "bear",
  data.dir = data.dir,
  working.dir = working.dir)
```

## Model fitting

The next step is to fit the OPSCR model to the prepared bear data using NIMBLE.
In this example, as in most cases in the [**RovQuant**](https://www.nmbu.no/en/research/projects/rovquant) project, we fit sex-specific models.

```{r run_females1.1, eval=TRUE}

##-- List all prepared input files
inputFiles <- list.files( file.path(working.dir, "nimbleInFiles/female"),
                          full.names = T)

##-- Load the first one
load(inputFiles[1]) 

##-- Build nimble model object
model <- nimbleModel( code = modelCode,
                      constants = nimConstants,
                      inits = nimInits,
                      data = nimData,
                      check = FALSE,
                      calculate = FALSE) 
model$calculate()
cmodel <- compileNimble(model)
conf <- configureMCMC( model,
                       monitors = nimParams,
                       thin = 1,
                       monitors2 = nimParams2,
                       thin2 = 5)
Rmcmc <- buildMCMC(conf)
compiledList <- compileNimble( list(model = model,
                                    mcmc = Rmcmc),
                               showCompilerOutput = F)
Cmcmc <- compiledList$mcmc

##-- Run nimble MCMC in successive bites
system.time(runMCMCbites( mcmc = Cmcmc,
                          bite.size = 100,
                          bite.number = 10,
                          path = file.path(working.dir,"nimbleOutfiles/female")))


```

The first step when fitting a statistical model using NIMBLE is to create a model object, containing the model code, the constants/dimensions, data and initial values used in the model.

```{r run_females2, eval=TRUE}
model <- nimbleModel( code = modelCode,
                      constants = nimConstants,
                      inits = nimInits,
                      data = nimData,
                      check = FALSE,
                      calculate = FALSE) 
```

The second step is to compile the model in C++.

```{r run_females3, eval=TRUE}
cmodel <- compileNimble(model)
```

Next, we need to configure and compile the MCMC algorithm that will be used to sample posterior samples.

```{r run_females4, eval=TRUE}
conf <- configureMCMC( model,
                       monitors = nimParams,
                       thin = 1,
                       monitors2 = nimParams2,
                       thin2 = 5)
Rmcmc <- buildMCMC(conf)
compiledList <- compileNimble( list(model = model,
                                    mcmc = Rmcmc),
                               showCompilerOutput = F)
Cmcmc <- compiledList$mcmc
```

Finally, once the MCMC algorithm and the model are prepared and compiled, we can run it using the `runMCMCbites` function.
This function will split up the MCMC chain in multiple bites and save posterior samples as the MCMC algorithm is running.
This presents the double advantage of i) using less memory when fitting large scale models, and ii) allowing to check for the advancement of the MCMC process as sampling goes on (and also allowing to restart the MCMC chain should something go wrong).

```{r run_females5, eval=TRUE}
system.time(runMCMCbites( mcmc = Cmcmc,
                          bite.size = 100,
                          bite.number = 5,
                          path = file.path(working.dir,"nimbleOutfiles/Hunn")))

```

And now, we can do the same for males:

```{r run_males, eval=TRUE}
##-- List all prepared input files
inputFiles <- list.files( file.path(working.dir, "nimbleInFiles/male"),
                         full.names = T)

##-- Load the first one
load(inputFiles[1]) 

##-- Build nimble model object
model <- nimbleModel( code = modelCode,
                      constants = nimConstants,
                      inits = nimInits,
                      data = nimData,
                      check = FALSE,
                      calculate = FALSE) 
model$calculate()

cmodel <- compileNimble(model)
conf <- configureMCMC(model,
                      monitors = nimParams,
                      thin = 1,
                      monitors2 = nimParams2,
                      thin2 = 5)
Rmcmc <- buildMCMC(conf)
compiledList <- compileNimble(list(model = model,
                                   mcmc = Rmcmc),
                              showCompilerOutput = F)
Cmcmc <- compiledList$mcmc

##-- RUN NIMBLE MCMC IN SUCCESSIVE BITES
system.time(runMCMCbites( mcmc = Cmcmc,
                          bite.size = 100,
                          bite.number = 10,
                          path = file.path(working.dir,"nimbleOutfiles/male")))
```

# Output processing

Last but not least, we can now process the MCMC outputs generated by NIMBLE to extract results in a more meaningful manner.
Again, this last function prints out a `.html` report summarinzing the most important results from the model.
Additional results (like the traceplots allowing to check the convergence of the model) are saved in the `figures` and `tables` folders, and raster files of the population density maps are saved in the `rasters`folder.

```{r processRovquantOutput, eval = TRUE}
processRovquantOutput(   
  species = "Brown bear",
  data.dir = data.dir,
  working.dir = working.dir,
  nburnin = 0,
  niter = 100,
  extraction.res = 5000,
  print.report = TRUE,
  overwrite = FALSE)
```
